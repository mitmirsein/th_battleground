#!/usr/bin/env python3
"""
Phase 6: Report Visualization
Markdown â†’ Interactive HTML ë³€í™˜ ëª¨ë“ˆ

Usage:
    python visualize_session.py --topic {topic} [--mode full|condensed|both]
    
Input:
    - reports/{topic}_final.md (ë˜ëŠ” _annotated.md)
    - reports/{topic}_footnotes.json
    
Output:
    - reports/{topic}_report.html (full ëª¨ë“œ)
    - reports/{topic}_brief.html (condensed ëª¨ë“œ)
"""

import argparse
import json
import re
from pathlib import Path
from jinja2 import Environment, FileSystemLoader
import markdown


class Section:
    """ì„¹ì…˜ ë°ì´í„° í´ë˜ìŠ¤"""
    def __init__(self, title: str, content: str, level: int = 2,
                 essence: str = "", keywords: list = None):
        self.title = title
        self.nav_title = title[:12] + "..." if len(title) > 15 else title
        self.content = content
        self.level = level
        self.essence = essence
        self.keywords = keywords or []


class Footnote:
    """ê°ì£¼ ë°ì´í„° í´ë˜ìŠ¤"""
    def __init__(self, id: int, citation: str):
        self.id = id
        self.citation = citation


def extract_essence_and_keywords(content: str) -> tuple[str, list[str]]:
    """
    ì„¹ì…˜ ì½˜í…ì¸ ì—ì„œ essence(í•µì‹¬ ë¬¸ì¥)ì™€ keywords ì¶”ì¶œ
    
    - essence: ì²« ë²ˆì§¸ ì˜ë¯¸ ìˆëŠ” ë¬¸ì¥ (í•˜ìœ„ ì„¹ì…˜ í—¤ë”© ì œì™¸)
    - keywords: ëŒ€ë¬¸ìë¡œ ì‹œì‘í•˜ëŠ” í‚¤ì›Œë“œ, ì¸ìš©ë¬¸, ì£¼ìš” ìš©ì–´
    """
    # Essence ì¶”ì¶œ ê°œì„ 
    # 1. í—¤ë”©(h3~h6), ë¦¬ìŠ¤íŠ¸(ul, ol), í…Œì´ë¸”(table) íƒœê·¸ê°€ ë‚˜ì˜¤ê¸° ì „ê¹Œì§€ë§Œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (Intro)
    split_pattern = re.compile(r'<(h[3-6]|ul|ol|table)', re.IGNORECASE)
    parts = split_pattern.split(content, 1)
    
    intro_html = parts[0]
    
    # 2. íƒœê·¸ ì œê±° ë° í…ìŠ¤íŠ¸ ì •ì œ
    text = re.sub(r'<[^>]+>', '', intro_html)
    text = re.sub(r'\s+', ' ', text).strip()
    
    # Fallback: Introê°€ ë„ˆë¬´ ì§§ìœ¼ë©´(30ì ë¯¸ë§Œ) ë’·ë¶€ë¶„(parts[2]) í…ìŠ¤íŠ¸ë„ ê°€ì ¸ì˜´
    if len(text) < 30 and len(parts) > 2:
        # parts[1]ì€ ë§¤ì¹­ëœ íƒœê·¸ì´ë¯€ë¡œ ì œì™¸í•˜ê³  parts[2](ê·¸ ì´í›„ ë‚´ìš©) ì‚¬ìš©
        body_text = re.sub(r'<[^>]+>', '', parts[2])
        body_text = re.sub(r'\s+', ' ', body_text).strip()
        text += " " + body_text
    
    # 3. ë¬¸ì¥ ë¶„ë¦¬
    sentences = re.split(r'(?<=[.!?])\s+', text)
    
    essence = ""
    current_length = 0
    
    for sentence in sentences:
        sentence = sentence.strip()
        # ê±´ë„ˆë›¸ íŒ¨í„´ë“¤
        if re.match(r'^\d+\.?\s*$', sentence): continue
        if len(sentence) < 5: continue # ë„ˆë¬´ ì§§ì€ ê±´ ë¬´ì‹œ
        
        # 300ì ì œí•œ ì²´í¬
        if current_length + len(sentence) > 300:
            # ì²« ë¬¸ì¥ì¸ë° 300ì ë„˜ìœ¼ë©´ ì˜ë¼ì„œë¼ë„ ë„£ìŒ
            if current_length == 0:
                essence = sentence
            break
            
        essence += sentence + " "
        current_length += len(sentence) + 1
    
    essence = essence.strip()
    
    # ë„ˆë¬´ ê¸¸ë©´ ë§ˆì¹¨í‘œ/ì‰¼í‘œ ìœ„ì¹˜ì—ì„œ ìë¥´ê¸° (ìµœëŒ€ 300ì + ì—¬ìœ )
    if len(essence) > 300:
        # ë§ˆì¹¨í‘œ ìœ„ì¹˜ ì°¾ê¸°
        cut_pos = essence.rfind('.', 0, 300)
        if cut_pos == -1:
            cut_pos = essence.rfind(',', 0, 300)
        
        if cut_pos > 50:
            essence = essence[:cut_pos + 1]
        else:
            essence = essence[:297] + "..."
            
    # Keywords ì¶”ì¶œ (ì „ì²´ contentì—ì„œ)
    keywords = []
    
    # 1. ì˜ì–´ ëŒ€ë¬¸ì ë‹¨ì–´ (í•™ìˆ  ìš©ì–´)
    caps_words = re.findall(r'\b([A-Z][a-zA-Z]{2,})\b', content)
    for word in caps_words[:5]:
        if word not in ['The', 'This', 'That', 'These', 'Those', 'There']:
            keywords.append(word)
    
    # 2. ê´„í˜¸ ì•ˆ ì›ì–´ (ì˜ˆ: ì…°í‚¤ë‚˜(Schechina))
    foreign_terms = re.findall(r'\(([A-Za-z]+)\)', content)
    keywords.extend(foreign_terms[:3])
    
    # ì¤‘ë³µ ì œê±° ë° ìµœëŒ€ 5ê°œ
    keywords = list(dict.fromkeys(keywords))[:5]
    
    return essence, keywords


def parse_markdown_sections(md_content: str, extract_extras: bool = False) -> tuple[list[Section], str, str]:
    """
    ë§ˆí¬ë‹¤ìš´ì„ ì„¹ì…˜ë³„ë¡œ íŒŒì‹±
    
    ë‘ ê°€ì§€ ì„¹ì…˜ íŒ¨í„´ ì§€ì›:
    1. ## **1\. ì„œë¡ ...** (H2 í˜•ì‹)
    2. **2\. ì–´ì›ì ...** (Bold í…ìŠ¤íŠ¸ í˜•ì‹)
    
    ê°œì„ ì‚¬í•­:
    - ì½”ë“œ ë¸”ë¡ (```markdown) ë‚´ë¶€ ë³¸ë¬¸ ì¶”ì¶œ
    - escaped ë¬¸ì (\*\*, \\.) ì •ë¦¬
    - í•˜ìœ„ ì„¹ì…˜ (###) ì½˜í…ì¸ ë¡œ ë³‘í•©
    
    Args:
        extract_extras: Trueë©´ essenceì™€ keywordsë„ ì¶”ì¶œ (condensed ëª¨ë“œìš©)
    
    Returns:
        (sections, subtitle, abstract)
    """
    # 1. ì „ì²˜ë¦¬: ì½”ë“œ ë¸”ë¡ ë‚´ë¶€ ë³¸ë¬¸ ì¶”ì¶œ
    # ```markdown ... ``` íŒ¨í„´ ê²€ìƒ‰
    code_block_pattern = re.compile(r'```(?:markdown|md)?\s*\n(.*?)```', re.DOTALL)
    code_blocks = code_block_pattern.findall(md_content)
    if code_blocks:
        # ì²« ë²ˆì§¸ ì½”ë“œ ë¸”ë¡(Main Article)ë§Œ ì‚¬ìš©
        # Deliverable 2, 3 ë“±ì€ ì œì™¸
        md_content = code_blocks[0]
    
    # 2. ì „ì²˜ë¦¬: escaped ë¬¸ì ì •ë¦¬
    md_content = md_content.replace('\\*\\*', '**')
    md_content = md_content.replace('\\.', '.')
    md_content = md_content.replace('\\-', '-')
    
    lines = md_content.split('\n')
    sections = []
    current_section = None
    current_content = []
    
    # í•„í„°ë§í•  ë©”íƒ€ ì„¹ì…˜ë“¤ (Briefì—ì„œ ì œì™¸)
    META_SECTIONS = ['endnotes', 'bibliography', 'source comparison', 'references', 
                     'ì°¸ê³  ë¬¸í—Œ', 'ì°¸ê³ ë¬¸í—Œ', 'ì°¸ê³  ìë£Œ', 'endnote', 
                     'deliverable', 'source ledger', 'method',
                     'abstract', 'ì´ˆë¡']
    
    # ì²« ë²ˆì§¸ ì„¹ì…˜ ì „ ë‚´ìš© (abstractë¡œ ì‚¬ìš©)
    abstract_lines = []
    abstract = ""
    found_first_section = False
    subtitle = ""
    skip_current_section = False
    
    # ë©”ì¸ ì„¹ì…˜ íŒ¨í„´ (## ë¡œ ì‹œì‘í•˜ëŠ” H2 í—¤ë”©ë§Œ)
    # ### í•˜ìœ„ ì„¹ì…˜ì€ ì½˜í…ì¸ ë¡œ í¬í•¨
    
    for line in lines:
        # H1 ì œëª© ê±´ë„ˆë›°ê¸° (íƒ€ì´í‹€ë¡œ ì‚¬ìš©ë¨)
        if line.startswith('# ') and not line.startswith('## '):
            continue
        
        # --- êµ¬ë¶„ì„ ì€ ë¬´ì‹œ
        if line.strip() == '## ---' or line.strip() == '---' or line.strip() == '-----':
            continue
        
        # H2 ì„¹ì…˜ ê°ì§€: ## ë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸ë§Œ ìƒˆ ì„¹ì…˜
        if line.startswith('## '):
            section_title = line[3:].strip()
            
            # ë©”íƒ€ ì„¹ì…˜ í•„í„°ë§
            is_meta = any(meta in section_title.lower() for meta in META_SECTIONS)
            if is_meta:
                skip_current_section = True
                continue
            
            # ì œëª© ì •ë¦¬
            clean_title = section_title
            skipping_subsection = False # ìƒˆ ë©”ì¸ ì„¹ì…˜ ì‹œì‘ ì‹œ ë¦¬ì…‹
            
            # ì´ì „ ì„¹ì…˜ ì €ì¥
            if current_section and not skip_current_section:
                content_md = '\n'.join(current_content)
                # Apply Citation Styling
                content_md = re.sub(r'\(Source: \[?([a-zA-Z0-9]+)\]?\)', 
                      r'<span class="citation-source text-accent-teal font-mono font-bold text-xs cursor-help" title="Source ID: \1">[SRC:\1]</span>', 
                      content_md)
                      
                content_html = markdown.markdown(content_md, extensions=['tables', 'fenced_code'])
                
                # Abstract ì„¹ì…˜ ì²´í¬
                if any(x in current_section.lower() for x in ['abstract', 'ì´ˆë¡']):
                     # Clipboard contentëŠ” ë³´í†µ ì „ì²´ ë‚´ìš©ì„ ë‹´ê³  ìˆì„ ìˆ˜ ìˆìœ¼ë‚˜, ì—¬ê¸°ì„œëŠ” ì„¹ì…˜ëª…ìœ¼ë¡œ ê±¸ëŸ¬ëƒ„
                     if any(x in current_section.lower() for x in ['abstract', 'ì´ˆë¡']):
                        abstract = md_to_inline_html(content_md)
                # ë©”íƒ€ ì„¹ì…˜ í•„í„°ë§ (ë¶€ë¶„ ì¼ì¹˜ í—ˆìš©)
                elif not any(meta in current_section.lower() for meta in META_SECTIONS):
                    if extract_extras:
                        essence, keywords = extract_essence_and_keywords(content_html)
                        # essenceê°€ ë¹„ì–´ìˆìœ¼ë©´ contentì˜ ì²« 500ìë¥¼ ì‚¬ìš©
                        if not essence:
                            essence = content_html[:500].split('</p>')[0].replace('<p>', '').strip() + "..." if len(content_html) > 500 else content_html.strip()
                        sections.append(Section(current_section, content_html, 
                                              essence=essence, keywords=keywords))
                    else:
                        sections.append(Section(current_section, content_html))
            
            # ë¹ˆ ì œëª©ì´ë©´ ê±´ë„ˆë›°ê¸°
            if not clean_title or clean_title == '---':
                continue
            
            # ìƒˆ ì„¹ì…˜ ì‹œì‘
            current_section = clean_title
            current_content = []
            
            # ìƒˆ ì„¹ì…˜ì´ ë©”íƒ€ ì„¹ì…˜ì¸ì§€ í™•ì¸ (H2 ë ˆë²¨)
            skip_current_section = False
            if any(meta in current_section.lower() for meta in META_SECTIONS):
                 skip_current_section = True
            
            found_first_section = True
            
        elif line.startswith('###') or line.startswith('####'):
            # í•˜ìœ„ ì„¹ì…˜ì´ ë©”íƒ€ ì„¹ì…˜ì¸ì§€ í™•ì¸
            if any(meta in clean_title.lower() for meta in META_SECTIONS):
                skipping_subsection = True
            else:
                skipping_subsection = False
                if found_first_section and current_section and not skip_current_section:
                    current_content.append(line)
        
        elif found_first_section and current_section and not skip_current_section and not skipping_subsection:
            # H3, H4 ì„œë¸Œì„¹ì…˜ ë° ëª¨ë“  ì½˜í…ì¸ ë¥¼ í˜„ì¬ ì„¹ì…˜ì— í¬í•¨
            current_content.append(line)
        elif not found_first_section:
            # ì²« ì„¹ì…˜ ì „ ë‚´ìš© ìˆ˜ì§‘ (abstract í›„ë³´)
            # YAML frontmatter ë° ë©”íƒ€ë°ì´í„° ê±´ë„ˆë›°ê¸°
            if line.strip() and not line.startswith('---') and not line.startswith('title:') and not line.startswith('generated:') and not line.startswith('source:') and not line.startswith('phase:') and not line.startswith('**ë¶„ë¥˜**') and not line.startswith('**ì–¸ì–´**'):
                abstract_lines.append(line)
    
    # ì½”ë“œ ë¸”ë¡ ë‚´ë¶€ì˜ #, ## ëŠ” ë¬´ì‹œí•´ì•¼ í•¨
    # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
    if current_section and not skip_current_section:
        content_md = '\n'.join(current_content)
        # Apply Citation Styling
        content_md = re.sub(r'\(Source: \[?([a-zA-Z0-9]+)\]?\)', 
              r'<span class="citation-source text-accent-teal font-mono font-bold text-xs cursor-help" title="Source ID: \1">[SRC:\1]</span>', 
              content_md)

        content_html = markdown.markdown(content_md, extensions=['tables', 'fenced_code'])
        
        # Abstract ì„¹ì…˜ ì²´í¬ (ë§ˆì§€ë§‰ ì„¹ì…˜ì¸ ê²½ìš°)
        if any(x in current_section.lower() for x in ['abstract', 'ì´ˆë¡']):
            abstract = md_to_inline_html(content_md)
        # ë©”íƒ€ ì„¹ì…˜ í•„í„°ë§ (ë¶€ë¶„ ì¼ì¹˜ í—ˆìš©)
        elif not any(meta in current_section.lower() for meta in META_SECTIONS):
            if extract_extras:
                essence, keywords = extract_essence_and_keywords(content_html)
                # essenceê°€ ë¹„ì–´ìˆìœ¼ë©´ contentì˜ ì²« 500ìë¥¼ ì‚¬ìš©
                if not essence:
                    essence = content_html[:500].split('</p>')[0].replace('<p>', '').strip() + "..." if len(content_html) > 500 else content_html.strip()
                sections.append(Section(current_section, content_html,
                                      essence=essence, keywords=keywords))
            else:
                sections.append(Section(current_section, content_html))

    # ëª…ì‹œì  Abstract ì„¹ì…˜ì´ ì—†ìœ¼ë©´ ìˆ˜ì§‘ëœ ë¼ì¸ ì‚¬ìš©
    if not abstract:
        abstract_md = ' '.join(abstract_lines[:5])
        abstract_md = re.sub(r'\s+', ' ', abstract_md).strip()
        if len(abstract_md) > 300:
            abstract_md = abstract_md[:297] + "..."
        abstract = md_to_inline_html(abstract_md)
    
    return sections, subtitle, abstract


def extract_footnotes_from_json(json_path: Path) -> list[Footnote]:
    """JSON íŒŒì¼ì—ì„œ ê°ì£¼ ì¶”ì¶œ"""
    footnotes = []
    
    if not json_path.exists():
        print(f"Warning: {json_path} not found. Using empty footnotes.")
        return footnotes
    
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # bibliography ì‚¬ìš© (ìˆìœ¼ë©´)
        if 'bibliography' in data and data['bibliography']:
            for i, citation in enumerate(data['bibliography'], 1):
                footnotes.append(Footnote(i, citation))
        # ë˜ëŠ” footnotesì—ì„œ citation_chicago ì¶”ì¶œ
        elif 'footnotes' in data:
            for i, fn in enumerate(data['footnotes'], 1):
                citation = fn.get('citation_chicago', fn.get('citation', ''))
                if citation:
                    footnotes.append(Footnote(i, citation))
    except (json.JSONDecodeError, KeyError) as e:
        print(f"Warning: Error parsing {json_path}: {e}")
    
    return footnotes


def md_to_inline_html(text: str) -> str:
    """Markdown í…ìŠ¤íŠ¸ë¥¼ ì¸ë¼ì¸ HTMLë¡œ ë³€í™˜ (p íƒœê·¸ ì œê±° ë° ì¸ìš©êµ¬ ì²˜ë¦¬)"""
    # 1. (Source: [ID]) íŒ¨í„´ ì²˜ë¦¬ -> Styled Span
    # ì˜ˆ: (Source: [ebcf0275]) -> <span class="citation-source text-accent-teal font-bold text-xs" title="Source ID: ebcf0275">[SRC: ebcf0275]</span>
    text = re.sub(r'\(Source: \[?([a-zA-Z0-9]+)\]?\)', 
                  r'<span class="citation-source text-accent-teal font-mono font-bold text-xs cursor-help" title="Source ID: \1">[SRC:\1]</span>', 
                  text)
    
    html = markdown.markdown(text)
    if html.startswith('<p>') and html.endswith('</p>'):
        return html[3:-4]
    return html


def extract_bibliography_from_markdown(md_content: str) -> list[Footnote]:
    """ë§ˆí¬ë‹¤ìš´ ì°¸ê³ ë¬¸í—Œ ì„¹ì…˜ì—ì„œ í•­ëª© ì¶”ì¶œ"""
    footnotes = []
    
    # ì½”ë“œ ë¸”ë¡ ì „ì²˜ë¦¬
    code_block_pattern = re.compile(r'```(?:markdown|md)?\s*\n(.*?)```', re.DOTALL)
    code_blocks = code_block_pattern.findall(md_content)
    if code_blocks:
        md_content = '\n'.join(code_blocks)
    
    # ì°¸ê³ ë¬¸í—Œ ì„¹ì…˜ ì°¾ê¸° (ì—¬ëŸ¬ íŒ¨í„´ ì§€ì›)
    bib_patterns = [
        r'###?\s*(?:ğŸ“š\s*)?(?:ì„ ì •\s*)?ì°¸ê³ ë¬¸í—Œ.*?\n(.*?)(?=\n##|\n---|\Z)',
        r'###?\s*Selected Bibliography\s*\n(.*?)(?=\n##|\n---|\Z)',
        r'\*\*\[Primary Sources.*?\n(.*?)(?=\n##|\n---|\Z)',
    ]
    
    bib_content = ""
    for pattern in bib_patterns:
        match = re.search(pattern, md_content, re.DOTALL | re.IGNORECASE)
        if match:
            bib_content = match.group(1)
            break
    
    if not bib_content:
        return footnotes
    
    # ê° í•­ëª© ì¶”ì¶œ (* ë¡œ ì‹œì‘í•˜ëŠ” í•­ëª©ë“¤)
    items = re.findall(r'^\s*\*\s+(.+?)(?=\n\s*\*|\n\n|\n\*\*\[|\Z)', bib_content, re.MULTILINE | re.DOTALL)
    
    for i, item in enumerate(items, 1):
        citation_md = item.strip().replace('\n', ' ')
        if citation_md and len(citation_md) > 10:
            # Markdown ì´íƒ¤ë¦­/ë³¼ë“œ ë“±ì„ HTMLë¡œ ë³€í™˜
            citation_html = md_to_inline_html(citation_md)
            footnotes.append(Footnote(i, citation_html))
    
    return footnotes


def extract_footnotes_from_markdown(md_content: str) -> list[Footnote]:
    """ë§ˆí¬ë‹¤ìš´ ê°ì£¼ ì •ì˜ì—ì„œ ì¶”ì¶œ"""
    footnotes = []
    
    # [^n]: íŒ¨í„´ ì°¾ê¸°
    pattern = r'\[\^(\d+)\]:\s*(.+?)(?=\n\[\^|\n\n|\Z)'
    matches = re.findall(pattern, md_content, re.DOTALL)
    
    for id_str, citation in matches:
        # Markdownì„ HTMLë¡œ ë³€í™˜
        citation_html = md_to_inline_html(citation.strip())
        footnotes.append(Footnote(int(id_str), citation_html))
    
    return footnotes


def render_html(topic: str, sections: list[Section], footnotes: list[Footnote], 
                subtitle: str = "", abstract: str = "", 
                mode: str = "full") -> str:
    """Jinja2 í…œí”Œë¦¿ ë Œë”ë§"""
    
    # í…œí”Œë¦¿ ë””ë ‰í† ë¦¬ ì„¤ì •
    script_dir = Path(__file__).parent
    template_dir = script_dir / 'templates'
    
    env = Environment(loader=FileSystemLoader(template_dir))
    
    # ëª¨ë“œì— ë”°ë¥¸ í…œí”Œë¦¿ ì„ íƒ
    if mode == "condensed":
        template = env.get_template('condensed_template.html')
    else:
        template = env.get_template('base_template.html')
    
    # íƒ€ì´í‹€ ì •ë¦¬ (ì²« ë²ˆì§¸ ë‹¨ì–´ ë˜ëŠ” í† í”½ëª…)
    title = topic.replace('_', ' ').replace('-', ' ').title()
    
    # ì„œë¸Œíƒ€ì´í‹€ ê¸°ë³¸ê°’
    if not subtitle:
        subtitle = "Theological Research Report"
    
    # Abstract ê¸°ë³¸ê°’
    if not abstract:
        abstract = f"A comprehensive research report on {title}, generated by Gemini Scholar Pipeline."
    
    # Full report URL (condensedì—ì„œ ë§í¬ìš©)
    full_report_url = f"{topic}_report.html"
    
    # ë Œë”ë§
    html = template.render(
        title=title,
        subtitle=subtitle,
        abstract=abstract,
        sections=sections,
        footnotes=footnotes,
        quote=None,  # ì„ íƒì  ì¸ìš©ë¬¸ (ë¹„í™œì„±í™”)
        full_report_url=full_report_url
    )
    
    return html


def main():
    parser = argparse.ArgumentParser(description='Phase 6: Report Visualization')
    parser.add_argument('--topic', required=True, help='Topic name (e.g., justification)')
    parser.add_argument('--mode', choices=['full', 'condensed', 'both'], 
                        default='both', help='Visualization mode (default: both)')
    parser.add_argument('--suffix', default='', help='File name suffix (e.g., _research)')
    args = parser.parse_args()
    
    topic = args.topic
    mode = args.mode
    suffix = args.suffix
    script_dir = Path(__file__).parent
    reports_dir = script_dir / 'reports'
    
    # ì…ë ¥ íŒŒì¼ ê²½ë¡œ
    final_md = reports_dir / f'{topic}_final.md'
    annotated_md = reports_dir / f'{topic}_annotated.md'
    footnotes_json = reports_dir / f'{topic}_footnotes.json'
    
    # _final.md ìš°ì„ , ì—†ìœ¼ë©´ _annotated.md ì‚¬ìš©
    if final_md.exists():
        md_path = final_md
    elif annotated_md.exists():
        md_path = annotated_md
    else:
        print(f"Error: No input file found. Expected:")
        print(f"  - {final_md}")
        print(f"  - {annotated_md}")
        return
    
    print(f"[Phase 6] Report Visualization")
    print(f"  Input: {md_path.name}")
    print(f"  Mode: {mode}")
    
    # ë§ˆí¬ë‹¤ìš´ ì½ê¸°
    with open(md_path, 'r', encoding='utf-8') as f:
        md_content = f.read()
    
    # ê°ì£¼ ì¶”ì¶œ (JSON ìš°ì„ , ì—†ìœ¼ë©´ ë§ˆí¬ë‹¤ìš´ì—ì„œ)
    footnotes = extract_footnotes_from_json(footnotes_json)
    if not footnotes:
        # ë§ˆí¬ë‹¤ìš´ ê°ì£¼ ì •ì˜ì—ì„œ ì¶”ì¶œ
        footnotes = extract_footnotes_from_markdown(md_content)
    if not footnotes:
        # ì°¸ê³ ë¬¸í—Œ ì„¹ì…˜ì—ì„œ ì¶”ì¶œ
        footnotes = extract_bibliography_from_markdown(md_content)
    print(f"  Footnotes found: {len(footnotes)}")
    
    # Full ëª¨ë“œ ìƒì„±
    if mode in ['full', 'both']:
        sections, subtitle, abstract = parse_markdown_sections(md_content, extract_extras=False)
        print(f"  [Full] Sections parsed: {len(sections)}")
        
        html = render_html(topic, sections, footnotes, subtitle, abstract, mode="full")
        output_path = reports_dir / f'{topic}{suffix}_report.html'
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html)
        print(f"  [Full] Output: {output_path.name}")
    
    # Condensed ëª¨ë“œ ìƒì„±
    if mode in ['condensed', 'both']:
        sections, subtitle, abstract = parse_markdown_sections(md_content, extract_extras=True)
        print(f"  [Condensed] Sections parsed: {len(sections)}")
        
        html = render_html(topic, sections, footnotes, subtitle, abstract, mode="condensed")
        output_path = reports_dir / f'{topic}{suffix}_brief.html'
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html)
        print(f"  [Condensed] Output: {output_path.name}")
    
    print(f"[Phase 6] Complete!")


if __name__ == '__main__':
    main()
