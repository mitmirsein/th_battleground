#!/usr/bin/env python3
"""
Theology Research Orchestrator v2.1
====================================

50ëª…ì˜ AI ì‹ í•™ìë¥¼ ì§€íœ˜í•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°.

4-Tier ì •ë°€ ëª¨ë¸ ë§¤í•‘:
- LITE: íŒ€ êµ¬ì„±/ë¼ìš°íŒ…/êµ¬ì¡° ê²€ìˆ˜ ($0.10)
- WORKER: RAG ë…í•´/ì´ˆì•ˆ ì‘ì„± ($0.15)
- THINKER: ë…¼ë¦¬ ì¶”ë¡ /ë¶„ì„ (Thinking Mode)
- COMMANDER: ë‚´ì‰¬ ê· í˜•/ìµœì¢… í¸ì§‘ ($2.00)

Usage:
    python theology_orchestrator.py
    
Requirements:
    pip install -U google-generativeai python-dotenv
"""

import re
import os
from dotenv import load_dotenv
from google import genai
from google.genai import types

# ==============================================================================
# 1. ì„¤ì • (Configuration)
# ==============================================================================

# .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
load_dotenv()

def init_genai():
    """Gemini API ì´ˆê¸°í™” (í•„ìš”ì‹œ í˜¸ì¶œ)"""
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("âŒ GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   .env íŒŒì¼ì— GOOGLE_API_KEY=your_key_here í˜•ì‹ìœ¼ë¡œ ì¶”ê°€í•˜ì„¸ìš”.")
        print("   ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì„¸ìš”: export GOOGLE_API_KEY=your_key_here")
        return None
    return genai.Client(api_key=api_key)


# ëª¨ë¸ ìƒì„¸ ì •ì˜ (ê°€ê²©/ì„±ëŠ¥ ìµœì í™” ë§¤í•‘)
# ìµœì‹  ëª¨ë¸ëª… (2025-12 ê¸°ì¤€): https://ai.google.dev/gemini-api/docs/models
MODEL_REGISTRY = {
    "LITE": "gemini-3-flash-preview",         # ìµœì €ê°€ - ë¹ ë¥¸ ë¶„ë¥˜/ê²€ìˆ˜
    "WORKER": "gemini-3-flash-preview",       # ê°€ì„±ë¹„ - ì´ˆì•ˆ ì‘ì„±/ë…í•´
    "THINKER": "gemini-3-flash-preview",      # Thinking ëª¨ë“œ í™œì„±í™”
    "COMMANDER": "gemini-3-flash-preview"     # ìµœê³  ì„±ëŠ¥ - ë³µì¡í•œ ì¶”ë¡ /ì¢…í•©
}

# ëª¨ë¸ë³„ ì…ë ¥ ë¹„ìš© (1M í† í° ê¸°ì¤€, USD)
MODEL_COSTS = {
    "LITE": 0.10,
    "WORKER": 0.15,
    "THINKER": 0.15,  # ì…ë ¥ì€ ë™ì¼, ì¶œë ¥ì´ ë‹¤ë¦„
    "COMMANDER": 2.00
}

# ì•ˆì „ ì„¤ì • (ì—°êµ¬ìš©ì´ë¯€ë¡œ ì°¨ë‹¨ ê¸°ì¤€ì„ ë‚®ì¶¤)
SAFETY_SETTINGS = [
    types.SafetySetting(
        category="HARM_CATEGORY_HARASSMENT",
        threshold="BLOCK_NONE"
    ),
    types.SafetySetting(
        category="HARM_CATEGORY_HATE_SPEECH",
        threshold="BLOCK_NONE"
    ),
    types.SafetySetting(
        category="HARM_CATEGORY_SEXUALLY_EXPLICIT",
        threshold="BLOCK_NONE"
    ),
    types.SafetySetting(
        category="HARM_CATEGORY_DANGEROUS_CONTENT",
        threshold="BLOCK_NONE"
    ),
]

# ==============================================================================
# 2. í˜ë¥´ì†Œë‚˜ ê´€ë¦¬ì (Persona Manager)
# ==============================================================================

class PersonaManager:
    """ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì—ì„œ ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
    
    def __init__(self, file_path):
        self.personas = {}
        self._load_personas(file_path)

    def _load_personas(self, file_path):
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"âŒ í˜ë¥´ì†Œë‚˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")

        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # '# í˜ë¥´ì†Œë‚˜ ì´ë¦„' íŒ¨í„´ìœ¼ë¡œ ë¶„ë¦¬
        sections = re.split(r'^#\s+(.+)$', content, flags=re.MULTILINE)
        
        # split ê²°ê³¼: [ì„œë¬¸, ì œëª©1, ë‚´ìš©1, ì œëª©2, ë‚´ìš©2, ...]
        for i in range(1, len(sections), 2):
            name = sections[i].strip()
            body = sections[i+1].strip() if i+1 < len(sections) else ""
            
            # ë©”íƒ€ë°ì´í„° íŒŒì‹± (Tier, Pruning)
            tier = "Worker"  # ê¸°ë³¸ê°’
            pruning = None
            model_id = None
            
            # Tier ì¶”ì¶œ
            tier_match = re.search(r'\- \*\*Tier\*\*: (\w+)', body)
            if tier_match:
                tier = tier_match.group(1)
            
            # Model ID ì¶”ì¶œ (ìˆëŠ” ê²½ìš°)
            model_match = re.search(r'\- \*\*Model ID\*\*: `?(\w+)`?', body)
            if model_match:
                model_id = model_match.group(1)
            
            # Pruning ì „ëµ ì¶”ì¶œ
            pruning_match = re.search(r'\- \*\*Input Pruning\*\*: (.+)', body)
            if pruning_match:
                pruning_text = pruning_match.group(1)
                if "í•´ë‹¹ ì—†ìŒ" not in pruning_text:
                    pruning = pruning_text.strip()

            self.personas[name] = {
                "instruction": body,
                "tier": tier,
                "model_id": model_id,
                "pruning": pruning
            }

    def get_persona(self, name):
        """í˜ë¥´ì†Œë‚˜ ì´ë¦„ìœ¼ë¡œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°"""
        return self.personas.get(name)
    
    def find_persona(self, keyword):
        """í‚¤ì›Œë“œë¡œ í˜ë¥´ì†Œë‚˜ ì°¾ê¸° (ë¶€ë¶„ ì¼ì¹˜)"""
        for name, config in self.personas.items():
            if keyword.lower() in name.lower():
                return name, config
        return None, None
    
    def list_personas(self):
        """ëª¨ë“  í˜ë¥´ì†Œë‚˜ ëª©ë¡ ì¶œë ¥"""
        print("\nğŸ“‹ ë“±ë¡ëœ ì „ë¬¸ê°€ ëª©ë¡:")
        print("-" * 60)
        for name, config in self.personas.items():
            tier = config.get('tier', 'Worker')
            pruning = "âœ‚ï¸" if config.get('pruning') else ""
            print(f"  [{tier:10}] {name} {pruning}")
        print("-" * 60)
        print(f"  ì´ {len(self.personas)}ëª…ì˜ ì „ë¬¸ê°€")

# ==============================================================================
# 3. ì»¨í…ìŠ¤íŠ¸ í”„ë£¨ë‹ (Context Pruning)
# ==============================================================================

def apply_context_pruning(context_data: str, pruning_strategy: str, max_length: int = 3000) -> str:
    """
    ì»¨í…ìŠ¤íŠ¸ ê°€ì§€ì¹˜ê¸° ì ìš©
    
    Args:
        context_data: ì›ë³¸ ì»¨í…ìŠ¤íŠ¸
        pruning_strategy: í”„ë£¨ë‹ ì „ëµ ì„¤ëª…
        max_length: ìµœëŒ€ ê¸¸ì´
        
    Returns:
        ê°€ì§€ì¹˜ê¸°ëœ ì»¨í…ìŠ¤íŠ¸
    """
    if not context_data or len(context_data) <= max_length:
        return context_data
    
    # ê°„ë‹¨í•œ ìš”ì•½ ë°©ì‹ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë¡œì§ í•„ìš”)
    return f"[ìš”ì•½ëœ ì»¨í…ìŠ¤íŠ¸ - {pruning_strategy}]\n{context_data[:max_length]}...\n(ì´í•˜ {len(context_data) - max_length}ì ìƒëµ)"

# ==============================================================================
# 4. ë¦¬ì„œì¹˜ ì—”ì§„ (Research Engine)
# ==============================================================================

class TheologyResearchEngine:
    """ì‹ í•™ ì—°êµ¬ ì‹¤í–‰ ì—”ì§„"""
    
    def __init__(self, persona_manager: PersonaManager, client: genai.Client):
        self.pm = persona_manager
        self.client = client
        self.execution_log = []

    def _get_model_id(self, tier: str, override_model: str = None) -> str:
        """Tierì— ë§ëŠ” ìµœì  ëª¨ë¸ ID ë°˜í™˜"""
        if override_model and override_model in MODEL_REGISTRY:
            return MODEL_REGISTRY[override_model]
        return MODEL_REGISTRY.get(tier.upper(), MODEL_REGISTRY["WORKER"])

    def _get_generation_config(self, tier: str) -> types.GenerateContentConfig:
        """Tierì— ë§ëŠ” generation config ë°˜í™˜"""
        config = {
            "temperature": 0.7,
            "top_p": 0.95,
            "max_output_tokens": 8192,
        }
        
        if tier.upper() == "THINKER":
            # Thinking Mode ì„¤ì • (API ë²„ì „ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
            config["temperature"] = 0.5
            
        elif tier.upper() == "COMMANDER":
            # CommanderëŠ” ìµœëŒ€ í’ˆì§ˆ
            config["temperature"] = 0.3
            config["max_output_tokens"] = 16384
            
        elif tier.upper() == "LITE":
            # LiteëŠ” ë¹ ë¥¸ ì‘ë‹µ
            config["temperature"] = 0.1
            config["max_output_tokens"] = 2048
            
        return types.GenerateContentConfig(**config, safety_settings=SAFETY_SETTINGS)

    def run_agent(
        self, 
        persona_name: str, 
        task_input: str, 
        context_data: str = "",
        verbose: bool = True
    ) -> str:
        """
        ì§€ì •ëœ ì „ë¬¸ê°€ ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
        ìë™ìœ¼ë¡œ ëª¨ë¸ì„ ìŠ¤ìœ„ì¹­í•˜ê³ , ì»¨í…ìŠ¤íŠ¸ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤.
        
        Args:
            persona_name: í˜ë¥´ì†Œë‚˜ ì´ë¦„
            task_input: ìˆ˜í–‰í•  íƒœìŠ¤í¬
            context_data: RAG ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°
            verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€
            
        Returns:
            ì—ì´ì „íŠ¸ ì‘ë‹µ í…ìŠ¤íŠ¸
        """
        config = self.pm.get_persona(persona_name)
        if not config:
            # ë¶€ë¶„ ì¼ì¹˜ë¡œ ì¬ì‹œë„
            found_name, config = self.pm.find_persona(persona_name)
            if config:
                persona_name = found_name
            else:
                return f"âŒ Error: '{persona_name}'ë¼ëŠ” ì „ë¬¸ê°€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        tier = config.get('tier', 'Worker')
        model_id = self._get_model_id(tier, config.get('model_id'))
        gen_config = self._get_generation_config(tier)
        
        if verbose:
            print(f"\nğŸš€ [{persona_name}] ê°€ë™ ì‹œì‘...")
            print(f"   âš™ï¸  Model: {model_id} (Tier: {tier})")

        # 1. ì»¨í…ìŠ¤íŠ¸ ê°€ì§€ì¹˜ê¸° (Context Pruning)
        final_context = context_data
        if config.get('pruning'):
            if verbose:
                print(f"   âœ‚ï¸  [Context Pruning] í™œì„±í™”: {config['pruning']}")
            final_context = apply_context_pruning(context_data, config['pruning'])

        # 2. Thinking Mode ë¡œê·¸
        if tier.upper() == "THINKER" and verbose:
            print("   ğŸ§  [Thinking Mode] ë…¼ë¦¬ì  ì¶”ë¡  ê°•í™”")

        # 3. ëª¨ë¸ í˜¸ì¶œ
        try:
            prompt = f"""
{config['instruction']}

============================================================
[ì œê³µëœ ë°ì´í„° / RAG Context]
{final_context if final_context else "(ì—†ìŒ)"}
============================================================

[í˜„ì¬ ì„ë¬´ / TASK]
{task_input}
"""

            response = self.client.models.generate_content(
                model=model_id,
                contents=prompt,
                config=gen_config
            )
            
            if verbose:
                print("   âœ… ì‘ì—… ì™„ë£Œ.")
            
            # ì‹¤í–‰ ë¡œê·¸ ì €ì¥
            self.execution_log.append({
                "persona": persona_name,
                "tier": tier,
                "model": model_id,
                "task": task_input[:100],
                "status": "success"
            })
            
            return response.text
            
        except Exception as e:
            error_msg = f"   âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            self.execution_log.append({
                "persona": persona_name,
                "tier": tier,
                "model": model_id,
                "task": task_input[:100],
                "status": "error",
                "error": str(e)
            })
            return error_msg

    def estimate_cost(self, persona_list: list, avg_input_tokens: int = 50000) -> float:
        """ì˜ˆìƒ ë¹„ìš© ê³„ì‚°"""
        total_cost = 0.0
        for persona_name in persona_list:
            config = self.pm.get_persona(persona_name)
            if not config:
                _, config = self.pm.find_persona(persona_name)
            
            if config:
                tier = config.get('tier', 'Worker').upper()
                cost_per_million = MODEL_COSTS.get(tier, 0.15)
                total_cost += (avg_input_tokens / 1_000_000) * cost_per_million
        return total_cost

    def print_execution_summary(self):
        """ì‹¤í–‰ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ“Š ì‹¤í–‰ ìš”ì•½")
        print("=" * 60)
        
        success_count = sum(1 for log in self.execution_log if log['status'] == 'success')
        error_count = sum(1 for log in self.execution_log if log['status'] == 'error')
        
        print(f"  âœ… ì„±ê³µ: {success_count}")
        print(f"  âŒ ì‹¤íŒ¨: {error_count}")
        print(f"  ğŸ“ ì´ í˜¸ì¶œ: {len(self.execution_log)}")
        
        # í‹°ì–´ë³„ í˜¸ì¶œ ìˆ˜
        tier_counts = {}
        for log in self.execution_log:
            tier = log['tier']
            tier_counts[tier] = tier_counts.get(tier, 0) + 1
        
        print("\n  ğŸ·ï¸  í‹°ì–´ë³„ í˜¸ì¶œ:")
        for tier, count in tier_counts.items():
            print(f"      - {tier}: {count}íšŒ")

# ==============================================================================
# 5. ë©”ì¸ í”„ë¡¬í”„íŠ¸ ë¡œë” (Main Prompt Loader)
# ==============================================================================

def load_main_prompt(script_dir: str) -> str:
    """ë©”ì¸ í”„ë¡¬í”„íŠ¸ v1.4 ë¡œë“œ"""
    prompt_file = os.path.join(script_dir, "theological_research_v1.4.md")
    if os.path.exists(prompt_file):
        with open(prompt_file, 'r', encoding='utf-8') as f:
            return f.read()
    return ""

# ==============================================================================
# 6. ì—°êµ¬ ì›Œí¬í”Œë¡œìš° (Research Workflow)
# ==============================================================================

def run_research(topic: str, rag_context: str = "", output_dir: str = None):
    """
    ì—°êµ¬ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    
    Args:
        topic: ì—°êµ¬ ì£¼ì œ
        rag_context: RAG ì»¨í…ìŠ¤íŠ¸ (ì„ íƒ)
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (ì„ íƒ)
    """
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
    PERSONA_FILE = os.path.join(SCRIPT_DIR, "personas_all.md")
    
    if output_dir is None:
        output_dir = os.path.join(SCRIPT_DIR, "research_outputs")
    os.makedirs(output_dir, exist_ok=True)
    
    # API ì´ˆê¸°í™”
    client = init_genai()
    if not client:
        return None
    
    # 1. ë§¤ë‹ˆì € ì´ˆê¸°í™”
    print("ğŸ“š ë””ì§€í„¸ ì‹ í•™ëŒ€í•™ êµìˆ˜ì§„ì„ ì†Œì§‘í•©ë‹ˆë‹¤...")
    try:
        manager = PersonaManager(PERSONA_FILE)
        engine = TheologyResearchEngine(manager, client)
        print(f"âœ… ì´ {len(manager.personas)}ëª…ì˜ ì „ë¬¸ê°€ê°€ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤.\n")
    except Exception as e:
        print(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None
    
    # ë©”ì¸ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    main_prompt = load_main_prompt(SCRIPT_DIR)
    if main_prompt:
        print("ğŸ“œ ë©”ì¸ í”„ë¡¬í”„íŠ¸ v1.4 ë¡œë“œë¨")
    
    # --- ì—°êµ¬ ì‹œì‘ ---
    print("\n" + "=" * 60)
    print(f"ğŸ”¬ ì—°êµ¬ ì£¼ì œ: {topic}")
    print("=" * 60)
    
    # ë¹„ìš© ì¶”ì •
    team = ["ì„±ê²½ì‹ í•™ì", "í¸í–¥", "ë¶„ì„ì‹ í•™ì", "ìµœì¢… í¸ì§‘ì"]
    estimated_cost = engine.estimate_cost(team)
    print(f"\nğŸ’° ì˜ˆìƒ ë¹„ìš©: ${estimated_cost:.4f}")
    
    # Phase 1: [Worker] ì„±ê²½ì‹ í•™ì ì´ˆì•ˆ
    print("\nğŸ“ Phase 1: ì„±ê²½ì‹ í•™ì ì´ˆì•ˆ ì‘ì„±...")
    report_1 = engine.run_agent(
        "ì„±ê²½ì‹ í•™ì (Biblical Theologian)", 
        f"'{topic}'ì— ëŒ€í•´ ì„±ì„œì‹ í•™ì  ê´€ì ì—ì„œ ì´ˆì•ˆì„ ì‘ì„±í•´ì¤˜. í•µì‹¬ ì„±ê²½ ë³¸ë¬¸ê³¼ ì‹ í•™ì  ìŸì ì„ ë¶„ì„í•˜ë¼.",
        context_data=rag_context
    )
    
    # Phase 2: [Thinker] ë¶„ì„ì‹ í•™ì ë…¼ë¦¬ ê²€ì¦
    print("\nğŸ§  Phase 2: ë¶„ì„ì‹ í•™ì ë…¼ë¦¬ ê²€ì¦...")
    analysis_report = engine.run_agent(
        "ë¶„ì„ì‹ í•™ì (Analytic Theologian)",
        f"ìœ„ ì„±ê²½ì‹ í•™ìì˜ ë³´ê³ ì„œì—ì„œ ë…¼ë¦¬ì  íƒ€ë‹¹ì„±ì„ ê²€ì¦í•˜ê³ , ê°€ëŠ¥í•œ ë°˜ë¡€ì™€ ëŒ€ì•ˆì  ì„¤ëª…ì„ íƒêµ¬í•˜ë¼.",
        context_data=report_1
    )
    
    # Phase 3: [Auditor] í¸í–¥ ê°ì‚¬
    print("\nğŸ” Phase 3: í¸í–¥ ê°ì‚¬...")
    audit_report = engine.run_agent(
        "í¸í–¥ ë° ì „ìŠ¹ ê°ì‚¬ ì „ë¬¸ê°€ (Bias and Tradition Auditor)",
        "ìœ„ ë³´ê³ ì„œë“¤ì´ ì„œêµ¬ ì¤‘ì‹¬ì ì´ê±°ë‚˜ íŠ¹ì • êµíŒŒì— í¸í–¥ë˜ì—ˆëŠ”ì§€ ì ê²€í•˜ê³ , ê· í˜•ì¡íŒ ê´€ì ì„ ì œì‹œí•˜ë¼.",
        context_data=f"=== ì´ˆì•ˆ ===\n{report_1}\n\n=== ë¶„ì„ ===\n{analysis_report}"
    )

    # Phase 4: [Commander] ìµœì¢… ì¢…í•©
    print("\nâš”ï¸ Phase 4: Nash Equilibrium ì¢…í•© (Commander)...")
    final_paper = engine.run_agent(
        "ìµœì¢… í¸ì§‘ì (Final Editor)",
        f"""
        ì—°êµ¬ ì£¼ì œ: {topic}
        
        ì•„ë˜ ìë£Œë¥¼ ì¢…í•©í•˜ì—¬ Nash Equilibriumì„ ê°–ì¶˜ ìµœì¢… í•™ìˆ  ë…¼ë¬¸ì„ ì‘ì„±í•˜ë¼.
        - ì–´ë–¤ ì‹ í•™ ì „í†µ(ê°œí˜, ê°€í†¨ë¦­, ì •êµíšŒ)ì—ì„œë„ íŒŒí›¼ ë¶ˆê°€ëŠ¥í•œ ê· í˜•ì ì„ ì°¾ìœ¼ë¼.
        - SBL ì¸ìš© í˜•ì‹ì„ ì¤€ìˆ˜í•˜ë¼.
        """,
        context_data=f"=== ì´ˆì•ˆ ===\n{report_1}\n\n=== ë¶„ì„ ===\n{analysis_report}\n\n=== ê°ì‚¬ ===\n{audit_report}"
    )

    # ê²°ê³¼ ì €ì¥
    safe_topic = topic.replace(" ", "_").replace("/", "-")[:30]
    output_file = os.path.join(output_dir, f"{safe_topic}_final.md")
    
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(f"# ì—°êµ¬ ì£¼ì œ: {topic}\n\n")
        f.write("## ì—°êµ¬ ë©”íƒ€ë°ì´í„°\n")
        f.write(f"- ìƒì„±ì¼: {os.popen('date').read().strip()}\n")
        f.write(f"- ëª¨ë¸: 4-Tier Architecture (LITE/WORKER/THINKER/COMMANDER)\n")
        f.write(f"- í”„ë¡¬í”„íŠ¸: theological_research_v1.4.md\n\n")
        f.write("---\n\n")
        f.write(final_paper)
    
    # ì‹¤í–‰ ìš”ì•½
    engine.print_execution_summary()
    
    print(f"\nğŸ‰ ëª¨ë“  ì—°êµ¬ ê³¼ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"ğŸ“„ ê²°ê³¼ íŒŒì¼: {output_file}")
    
    return output_file

# ==============================================================================
# 7. CLI ì¸í„°í˜ì´ìŠ¤ (Command Line Interface)
# ==============================================================================

def main():
    """CLI ì§„ì…ì """
    import argparse
    
    parser = argparse.ArgumentParser(
        description="ğŸ“ Theology Research Orchestrator v2.1",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  python theology_orchestrator.py --topic "ì¹­ì˜ë¡ "
  python theology_orchestrator.py --topic "ì‚¼ìœ„ì¼ì²´" --rag context.txt
  python theology_orchestrator.py --interactive
        """
    )
    parser.add_argument(
        "--topic", "-t",
        type=str,
        help="ì—°êµ¬ ì£¼ì œ (í•„ìˆ˜ ë˜ëŠ” --interactive ì‚¬ìš©)"
    )
    parser.add_argument(
        "--rag", "-r",
        type=str,
        help="RAG ì»¨í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ (ì„ íƒ)"
    )
    parser.add_argument(
        "--output", "-o",
        type=str,
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: research_outputs/)"
    )
    parser.add_argument(
        "--interactive", "-i",
        action="store_true",
        help="ëŒ€í™”í˜• ëª¨ë“œë¡œ ì‹¤í–‰"
    )
    parser.add_argument(
        "--list-personas",
        action="store_true",
        help="ë“±ë¡ëœ í˜ë¥´ì†Œë‚˜ ëª©ë¡ ì¶œë ¥"
    )
    
    args = parser.parse_args()
    
    # í˜ë¥´ì†Œë‚˜ ëª©ë¡ ì¶œë ¥
    if args.list_personas:
        SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
        manager = PersonaManager(os.path.join(SCRIPT_DIR, "personas_all.md"))
        manager.list_personas()
        return
    
    # RAG ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ
    rag_context = ""
    if args.rag:
        if os.path.exists(args.rag):
            with open(args.rag, 'r', encoding='utf-8') as f:
                rag_context = f.read()
            print(f"ğŸ“‚ RAG ì»¨í…ìŠ¤íŠ¸ ë¡œë“œë¨: {args.rag} ({len(rag_context)} chars)")
        else:
            print(f"âš ï¸ RAG íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.rag}")
    
    # ëŒ€í™”í˜• ëª¨ë“œ
    if args.interactive:
        print("\nğŸ“ Theology Research Orchestrator v2.1")
        print("=" * 50)
        topic = input("\nğŸ“ ì—°êµ¬ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        if not topic:
            print("âŒ ì—°êµ¬ ì£¼ì œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        
        rag_input = input("ğŸ“‚ RAG ì»¨í…ìŠ¤íŠ¸ (ì—†ìœ¼ë©´ Enter): ").strip()
        if rag_input and os.path.exists(rag_input):
            with open(rag_input, 'r', encoding='utf-8') as f:
                rag_context = f.read()
        
        run_research(topic, rag_context, args.output)
        return
    
    # CLI ëª¨ë“œ
    if args.topic:
        run_research(args.topic, rag_context, args.output)
    else:
        parser.print_help()
        print("\nğŸ’¡ íŒ: --topic 'ì£¼ì œ' ë˜ëŠ” --interactive ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()
