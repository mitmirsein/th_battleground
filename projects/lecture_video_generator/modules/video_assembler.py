"""
Video Assembler - FFmpegë¡œ ìŠ¬ë¼ì´ë“œ + ì˜¤ë””ì˜¤ â†’ MP4 ì˜ìƒ ì¡°ë¦½

Usage:
    from modules.video_assembler import VideoAssembler
    
    assembler = VideoAssembler()
    final_video = assembler.assemble(
        slides_dir="output/lecture/",
        audio_dir="output/lecture/",
        output_file="output/lecture/final.mp4"
    )
"""
import subprocess
import sys
from pathlib import Path
from dataclasses import dataclass
from typing import List, Optional, Tuple
import json

sys.path.insert(0, str(Path(__file__).parent.parent))

from config import OUTPUT_DIR


@dataclass
class VideoSegment:
    """ì˜ìƒ ì„¸ê·¸ë¨¼íŠ¸"""
    slide_path: str
    audio_path: str
    output_path: str
    duration: float = 0.0


class VideoAssembler:
    """FFmpeg ì˜ìƒ ì¡°ë¦½"""
    
    def __init__(self, ffmpeg_path: str = "ffmpeg"):
        self.ffmpeg = ffmpeg_path
        self._check_ffmpeg()
    
    def _check_ffmpeg(self):
        """FFmpeg ì„¤ì¹˜ í™•ì¸"""
        try:
            result = subprocess.run(
                [self.ffmpeg, "-version"],
                capture_output=True,
                text=True
            )
            if result.returncode != 0:
                raise RuntimeError("FFmpeg not working properly")
        except FileNotFoundError:
            raise RuntimeError(
                "FFmpeg not found. Install with: brew install ffmpeg"
            )
    
    def get_audio_duration(self, audio_path: str) -> float:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ê¸¸ì´ ì¡°íšŒ (ì´ˆ)"""
        result = subprocess.run(
            [
                "ffprobe", "-v", "quiet",
                "-show_entries", "format=duration",
                "-of", "json", audio_path
            ],
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            data = json.loads(result.stdout)
            return float(data.get("format", {}).get("duration", 0))
        return 0.0
    
    def create_segment(
        self,
        slide_path: str,
        audio_path: str,
        output_path: str,
        end_padding: float = 2.0  # ìŠ¬ë¼ì´ë“œ ì „í™˜ìš© íŒ¨ë”© (ì´ˆ)
    ) -> bool:
        """ë‹¨ì¼ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± (ìŠ¬ë¼ì´ë“œ + ì˜¤ë””ì˜¤ + ì „í™˜ íŒ¨ë”©)"""
        # ì˜¤ë””ì˜¤ ëì— íŒ¨ë”© ì¶”ê°€í•˜ëŠ” í•„í„°
        audio_filter = f"apad=pad_dur={end_padding}"
        
        cmd = [
            self.ffmpeg,
            "-y",  # ë®ì–´ì“°ê¸°
            "-loop", "1",  # ì´ë¯¸ì§€ ë°˜ë³µ
            "-i", slide_path,  # ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€
            "-i", audio_path,  # ì˜¤ë””ì˜¤
            "-af", audio_filter,  # ì˜¤ë””ì˜¤ ëì— 2ì´ˆ íŒ¨ë”©
            "-c:v", "libx264",
            "-preset", "ultrafast",  # ë¹ ë¥¸ ì¸ì½”ë”©
            "-tune", "stillimage",
            "-c:a", "aac",
            "-b:a", "192k",
            "-pix_fmt", "yuv420p",
            "-shortest",  # ì˜¤ë””ì˜¤ ê¸¸ì´ì— ë§ì¶¤
            output_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        return result.returncode == 0
    
    def _create_segment_task(self, args) -> Tuple[int, str, bool, float]:
        """ë³‘ë ¬ ì²˜ë¦¬ìš© ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± íƒœìŠ¤í¬ (ì²­í‚¹ëœ ì˜¤ë””ì˜¤ ì§€ì›)"""
        idx, slide, audios, output = args  # audiosëŠ” ë¦¬ìŠ¤íŠ¸
        
        # ì—¬ëŸ¬ ì˜¤ë””ì˜¤ íŒŒì¼ì´ë©´ ë¨¼ì € ë³‘í•©
        if len(audios) > 1:
            merged_audio = output.parent / f"merged_audio_{idx:02d}.wav"
            concat_success = self._concat_audio_files(audios, str(merged_audio))
            if not concat_success:
                return (idx, str(output), False, 0.0)
            audio_file = str(merged_audio)
        else:
            audio_file = str(audios[0])
        
        duration = self.get_audio_duration(audio_file)
        success = self.create_segment(str(slide), audio_file, str(output))
        
        # ì„ì‹œ ë³‘í•© ì˜¤ë””ì˜¤ ì •ë¦¬
        if len(audios) > 1:
            Path(audio_file).unlink(missing_ok=True)
        
        return (idx, str(output), success, duration)
    
    def _concat_audio_files(self, audio_files: List[Path], output_path: str) -> bool:
        """ì—¬ëŸ¬ ì˜¤ë””ì˜¤ íŒŒì¼ ë³‘í•©"""
        concat_file = Path(output_path).parent / "audio_concat_list.txt"
        
        with open(concat_file, "w") as f:
            for audio in audio_files:
                abs_path = Path(audio).absolute()
                f.write(f"file '{abs_path}'\n")
        
        cmd = [
            self.ffmpeg,
            "-y",
            "-f", "concat",
            "-safe", "0",
            "-i", str(concat_file),
            "-c", "copy",
            output_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if concat_file.exists():
            concat_file.unlink()
        
        return result.returncode == 0
    
    def concat_segments_with_fade(
        self,
        segment_paths: List[str],
        output_path: str,
        fade_duration: float = 1.0
    ) -> bool:
        """ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ í˜ì´ë“œ íš¨ê³¼ì™€ í•¨ê»˜ ë³‘í•© (xfade)"""
        if len(segment_paths) < 2:
            # í•˜ë‚˜ë¿ì´ë©´ ê·¸ëƒ¥ ë³µì‚¬
            return self.concat_segments(segment_paths, output_path)
            
        inputs = []
        filter_complex = []
        
        # í˜„ì¬ ëˆ„ì  ì˜¤í”„ì…‹ (ì²« ì˜ìƒì€ 0ë¶€í„° ì‹œì‘)
        offset = 0.0
        
        # ì²« ë²ˆì§¸ ì˜ìƒ ì…ë ¥
        inputs.append("-i")
        inputs.append(segment_paths[0])
        
        # ì²« ì˜ìƒ ê¸¸ì´
        duration = self.get_audio_duration(segment_paths[0])
        
        # ëˆ„ì  ì˜¤í”„ì…‹ ì—…ë°ì´íŠ¸ (ì˜ìƒ ê¸¸ì´ - í˜ì´ë“œ ì‹œê°„)
        # ì˜ˆ: 10ì´ˆ ì˜ìƒ, 1ì´ˆ í˜ì´ë“œ â†’ ë‹¤ìŒ ì˜ìƒì€ 9ì´ˆì— ì‹œì‘
        offset += duration - fade_duration
        
        # í•„í„° ì²´ì¸ êµ¬ì„±
        # [0][1]xfade=...[v1]; [v1][2]xfade=...[v2]...
        last_stream = "0"
        
        for i in range(1, len(segment_paths)):
            # ì…ë ¥ ì¶”ê°€
            inputs.append("-i")
            inputs.append(segment_paths[i])
            
            next_stream = f"v{i}"
            if i == len(segment_paths) - 1:
                next_stream = "v_out" # ë§ˆì§€ë§‰ ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì´ë¦„
            
            # xfade í•„í„° (ë¹„ë””ì˜¤)
            # transition=fade:duration=1:offset=9
            filter_complex.append(
                f"[{last_stream}][{i}:v]xfade=transition=fade:duration={fade_duration}:offset={offset:.3f}[{next_stream}]"
            )
            
            # ì˜¤ë””ì˜¤ í¬ë¡œìŠ¤í˜ì´ë“œ (acrossfade)
            # [0:a][1:a]acrossfade=d=1:c1=tri:c2=tri[a1]; [a1][2:a]acrossfade...
            # ì˜¤ë””ì˜¤ëŠ” ë³„ë„ ì²˜ë¦¬ê°€ ë³µì¡í•˜ë¯€ë¡œ ê°„ë‹¨íˆ mix ë˜ëŠ” concat ì‚¬ìš© ê¶Œì¥ë˜ë‚˜
            # ì—¬ê¸°ì„œëŠ” concat í•„í„°ë¥¼ ì‚¬ìš©í•´ ì˜¤ë””ì˜¤ëŠ” ì»· ì „í™˜ (ë³´í†µ ìŒì„±ì€ ê³µë°±ì´ ìˆì–´ ìì—°ìŠ¤ëŸ¬ì›€)
            # ë˜ëŠ” ë¯¹ì‹±ì„ í•´ì•¼ í•¨.
            # ì˜ìƒ ì‹±í¬ë¥¼ ìœ„í•´ ì˜¤ë””ì˜¤ë„ offsetì— ë§ì¶° ë¯¹ì‹±í•˜ëŠ”ê²Œ ì •ì„ì´ë‚˜, 
            # FFmpeg ëª…ë ¹ì–´ê°€ ë„ˆë¬´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìŒ.
            
            # ë‹¤ìŒ ì˜¤í”„ì…‹ ê³„ì‚°
            dur = self.get_audio_duration(segment_paths[i])
            offset += dur - fade_duration
            
            last_stream = next_stream

        # ì˜¤ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë‹¨ìˆœ concat (í˜ì´ë“œ ì—†ì´ ì´ì–´ë¶™ì„ - ëŒ€ì‚¬ ê²¹ì¹¨ ë°©ì§€)
        # í•˜ì§€ë§Œ ë¹„ë””ì˜¤ê°€ ê²¹ì¹˜ë¯€ë¡œ(fade duration ë§Œí¼), ì˜¤ë””ì˜¤ë„ ê²¹ì³ì•¼ ì‹±í¬ê°€ ë§ìŒ.
        # ë”°ë¼ì„œ ì˜¤ë””ì˜¤ë„ acrossfade í•„ìš”.
        
        # ì˜¤ë””ì˜¤ í•„í„° ì²´ì¸ ì¬êµ¬ì„±
        a_last_stream = "0:a"
        a_filter_complex = []
        
        for i in range(1, len(segment_paths)):
            a_next_stream = f"a{i}"
            if i == len(segment_paths) - 1:
                a_next_stream = "a_out"
                
            a_filter_complex.append(
                f"[{a_last_stream}][{i}:a]acrossfade=d={fade_duration}:c1=tri:c2=tri[{a_next_stream}]"
            )
            a_last_stream = a_next_stream
            
        full_filter = ";".join(filter_complex + a_filter_complex)
        
        cmd = [
            self.ffmpeg,
            "-y",
            *inputs,
            "-filter_complex", full_filter,
            "-map", "[v_out]",
            "-map", "[a_out]",
            "-c:v", "libx264",
            "-preset", "ultrafast",
            "-c:a", "aac",
            "-b:a", "192k",
            output_path
        ]
        
        # ëª…ë ¹ì–´ê°€ ë„ˆë¬´ ê¸¸ ê²½ìš° íŒŒì¼ë¡œ ì €ì¥í•´ì„œ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì€ filter_complex_script ì‚¬ìš©
        # ì—¬ê¸°ì„œëŠ” ì§ì ‘ ì‹¤í–‰ ì‹œë„
        try:
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                print(f"âš ï¸ xfade ì‹¤íŒ¨, ë‹¨ìˆœ ë³‘í•©ìœ¼ë¡œ ì „í™˜: {result.stderr[-200:]}")
                return self.concat_segments(segment_paths, output_path)
            return True
        except OSError:
            print("âš ï¸ ëª…ë ¹ì–´ ê¸¸ì´ ì´ˆê³¼ ë“± ì˜¤ë¥˜, ë‹¨ìˆœ ë³‘í•©ìœ¼ë¡œ ì „í™˜")
            return self.concat_segments(segment_paths, output_path)

    def concat_segments(
        self,
        segment_paths: List[str],
        output_path: str
    ) -> bool:
        """ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ í•˜ë‚˜ë¡œ ë³‘í•© (ë‹¨ìˆœ concat)"""
        # concat ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
        concat_file = Path(output_path).parent / "concat_list.txt"
        
        with open(concat_file, "w") as f:
            for seg in segment_paths:
                # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
                abs_path = Path(seg).absolute()
                f.write(f"file '{abs_path}'\n")
        
        cmd = [
            self.ffmpeg,
            "-y",
            "-f", "concat",
            "-safe", "0",
            "-i", str(concat_file),
            "-c", "copy",
            output_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if concat_file.exists():
            concat_file.unlink()
        
        return result.returncode == 0
    
    def assemble(
        self,
        slides_dir: str,
        audio_dir: str = None,
        output_file: str = None,
        cleanup_segments: bool = True,
        parallel_workers: int = 4,
        use_fade: bool = True,
        fade_duration: float = 1.0
    ) -> Optional[str]:
        """ì „ì²´ ì˜ìƒ ì¡°ë¦½ (ë³‘ë ¬ ì²˜ë¦¬)"""
        from concurrent.futures import ThreadPoolExecutor
        
        slides_path = Path(slides_dir)
        audio_path = Path(audio_dir or slides_dir)
        
        # ìŠ¬ë¼ì´ë“œ íŒŒì¼ ì°¾ê¸° (PNG)
        slide_files = sorted(slides_path.glob("slide_*.png"))
        if not slide_files:
            print("âŒ ìŠ¬ë¼ì´ë“œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (slide_*.png)")
            return None
        
        # ì˜¤ë””ì˜¤ íŒŒì¼ ì°¾ê¸° (WAV)
        audio_files = sorted(audio_path.glob("audio_*.wav"))
        if not audio_files:
            print("âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (audio_*.wav)")
            return None
        
        # ë§¤ì¹­
        pairs = self._match_files(slide_files, audio_files)
        if not pairs:
            print("âŒ ìŠ¬ë¼ì´ë“œ-ì˜¤ë””ì˜¤ ë§¤ì¹­ ì‹¤íŒ¨")
            return None
        
        print(f"ğŸ“Š ë§¤ì¹­ëœ ìŒ: {len(pairs)}ê°œ")
        print(f"ğŸš€ ë³‘ë ¬ ì²˜ë¦¬: {parallel_workers} workers")
        
        # ì„¸ê·¸ë¨¼íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
        segment_dir = slides_path / "segments"
        segment_dir.mkdir(exist_ok=True)
        
        # íƒœìŠ¤í¬ ì¤€ë¹„
        tasks = []
        for i, (slide, audio) in enumerate(pairs, 1):
            segment_file = segment_dir / f"segment_{i:02d}.mp4"
            tasks.append((i, slide, audio, segment_file))
        
        # ë³‘ë ¬ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±
        print(f"   ğŸ¬ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± ì¤‘...")
        segments = []
        
        with ThreadPoolExecutor(max_workers=parallel_workers) as executor:
            results = list(executor.map(self._create_segment_task, tasks))
        
        # ê²°ê³¼ ì •ë ¬ ë° ì¶œë ¥
        for idx, output, success, duration in sorted(results):
            if success:
                print(f"      âœ… ì„¸ê·¸ë¨¼íŠ¸ {idx}: {duration:.0f}ì´ˆ")
                segments.append(output)
            else:
                print(f"      âŒ ì„¸ê·¸ë¨¼íŠ¸ {idx}")
        
        if not segments:
            print("âŒ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± ì‹¤íŒ¨")
            return None
        
        # ë³‘í•©
        output = output_file or str(slides_path / "final.mp4")
        
        if use_fade:
            print(f"\nğŸ”— ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ì¤‘ (Fade: {fade_duration}s)...")
            success = self.concat_segments_with_fade(segments, output, fade_duration)
        else:
            print(f"\nğŸ”— ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ì¤‘ (ì»· ì „í™˜)...")
            success = self.concat_segments(segments, output)
        
        if success:
            # ì„¸ê·¸ë¨¼íŠ¸ ì •ë¦¬
            if cleanup_segments:
                for seg in segments:
                    Path(seg).unlink()
                segment_dir.rmdir()
            
            # ìµœì¢… ì˜ìƒ ì •ë³´
            total_duration = self.get_audio_duration(output)
            print(f"âœ… ìµœì¢… ì˜ìƒ: {output}")
            print(f"   ê¸¸ì´: {total_duration / 60:.1f}ë¶„")
            
            return output
        else:
            print("âŒ ë³‘í•© ì‹¤íŒ¨")
            return None
    
    def _match_files(
        self,
        slides: List[Path],
        audios: List[Path]
    ) -> List[Tuple[Path, List[Path]]]:
        """ìŠ¬ë¼ì´ë“œ-ì˜¤ë””ì˜¤ ë§¤ì¹­ (ì²­í‚¹ëœ ì˜¤ë””ì˜¤ ì§€ì›)"""
        import re
        
        # ìŠ¬ë¼ì´ë“œ ë²ˆí˜¸ ì¶”ì¶œ
        slide_dict = {}
        for s in slides:
            # slide_01.png â†’ 01
            match = s.stem.split("_")[-1]
            if match.isdigit():
                slide_dict[int(match)] = s
        
        # ì˜¤ë””ì˜¤ ë²ˆí˜¸ ì¶”ì¶œ (ì²­í‚¹ ì§€ì›: audio_01.wav, audio_01-1.wav, audio_01-2.wav)
        audio_dict = {}  # {ì„¹ì…˜ë²ˆí˜¸: [ì˜¤ë””ì˜¤íŒŒì¼ë“¤]}
        for a in audios:
            # audio_01.wav â†’ 01, audio_01-1.wav â†’ 01
            stem = a.stem  # "audio_01" or "audio_01-1"
            match = re.match(r'audio_(\d+)(?:-\d+)?$', stem)
            if match:
                section_num = int(match.group(1))
                if section_num not in audio_dict:
                    audio_dict[section_num] = []
                audio_dict[section_num].append(a)
        
        # ì˜¤ë””ì˜¤ ì •ë ¬ (audio_01-1, audio_01-2 ìˆœì„œ)
        for section_num in audio_dict:
            audio_dict[section_num] = sorted(audio_dict[section_num])
        
        # ê³µí†µ ë²ˆí˜¸ ë§¤ì¹­
        pairs = []
        common_nums = set(slide_dict.keys()) & set(audio_dict.keys())
        
        for num in sorted(common_nums):
            pairs.append((slide_dict[num], audio_dict[num]))
        
        return pairs


def main():
    """í…ŒìŠ¤íŠ¸"""
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python video_assembler.py <output_dir>")
        sys.exit(1)
    
    assembler = VideoAssembler()
    result = assembler.assemble(sys.argv[1])
    
    if result:
        print(f"\nğŸ‰ ì˜ìƒ ìƒì„± ì™„ë£Œ: {result}")
    else:
        print("\nâŒ ì˜ìƒ ìƒì„± ì‹¤íŒ¨")


if __name__ == "__main__":
    main()
