"""
TTS Generator - Gemini APIë¡œ ìŒì„± ìƒì„± (google-genai SDK)

Usage:
    from modules.tts_generator import TTSGenerator
    
    generator = TTSGenerator()
    audio_files = generator.generate_for_lecture(lecture)
"""
import sys
import time
import struct
import mimetypes
from pathlib import Path
from dataclasses import dataclass
from typing import List, Optional

sys.path.insert(0, str(Path(__file__).parent.parent))

from config import GOOGLE_API_KEY, TTS_MODEL, TTS_VOICE, OUTPUT_DIR
from modules.tts_preprocessor import TTSPreprocessor


@dataclass
class TTSResult:
    """TTS ê²°ê³¼"""
    section_num: int
    audio_path: str
    text: str
    duration_estimate: float


class TTSGenerator:
    """Gemini TTS ìŒì„± ìƒì„±ê¸° (google-genai SDK)"""
    
    def __init__(self, api_key: str = None, voice: str = None):
        self.api_key = api_key or GOOGLE_API_KEY
        self.voice = voice or TTS_VOICE
        self.model = TTS_MODEL
        self.preprocessor = TTSPreprocessor()
        self._client = None
    
    @property
    def client(self):
        """Lazy initialization of GenAI client"""
        if self._client is None:
            if not self.api_key:
                raise ValueError("GOOGLE_API_KEY not set. Check .env file.")
            
            from google import genai
            self._client = genai.Client(api_key=self.api_key)
        
        return self._client
    
    def generate(self, text: str, output_path: str) -> bool:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ TTS ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)"""
        try:
            from google.genai import types
            
            contents = [
                types.Content(
                    role="user",
                    parts=[types.Part.from_text(text=text)],
                )
            ]
            
            generate_content_config = types.GenerateContentConfig(
                temperature=1,
                response_modalities=["audio"],
                speech_config=types.SpeechConfig(
                    voice_config=types.VoiceConfig(
                        prebuilt_voice_config=types.PrebuiltVoiceConfig(
                            voice_name=self.voice
                        )
                    )
                ),
            )
            
            # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì˜¤ë””ì˜¤ ìˆ˜ì‹ 
            audio_data = b""
            mime_type = None
            
            for chunk in self.client.models.generate_content_stream(
                model=self.model,
                contents=contents,
                config=generate_content_config,
            ):
                if (
                    chunk.candidates is None
                    or chunk.candidates[0].content is None
                    or chunk.candidates[0].content.parts is None
                ):
                    continue
                    
                part = chunk.candidates[0].content.parts[0]
                if hasattr(part, 'inline_data') and part.inline_data and part.inline_data.data:
                    audio_data += part.inline_data.data
                    if mime_type is None:
                        mime_type = part.inline_data.mime_type
            
            if audio_data:
                # WAV ë³€í™˜
                wav_data = self._convert_to_wav(audio_data, mime_type or "audio/L16;rate=24000")
                
                with open(output_path, "wb") as f:
                    f.write(wav_data)
                
                # ì •ì (Silence) ì œê±° (FFmpeg)
                self._trim_silence(output_path)
                return True
            
            print(f"âš ï¸ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
                
        except Exception as e:
            print(f"âŒ TTS ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def _convert_to_wav(self, audio_data: bytes, mime_type: str) -> bytes:
        """Raw PCM ë°ì´í„°ë¥¼ WAVë¡œ ë³€í™˜"""
        # MIME íƒ€ì…ì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        bits_per_sample = 16
        sample_rate = 24000
        
        parts = mime_type.split(";")
        for param in parts:
            param = param.strip()
            if param.lower().startswith("rate="):
                try:
                    sample_rate = int(param.split("=", 1)[1])
                except (ValueError, IndexError):
                    pass
            elif param.startswith("audio/L"):
                try:
                    bits_per_sample = int(param.split("L", 1)[1])
                except (ValueError, IndexError):
                    pass
        
        # WAV í—¤ë” ìƒì„±
        num_channels = 1
        data_size = len(audio_data)
        bytes_per_sample = bits_per_sample // 8
        block_align = num_channels * bytes_per_sample
        byte_rate = sample_rate * block_align
        chunk_size = 36 + data_size
        
        header = struct.pack(
            "<4sI4s4sIHHIIHH4sI",
            b"RIFF",
            chunk_size,
            b"WAVE",
            b"fmt ",
            16,
            1,
            num_channels,
            sample_rate,
            byte_rate,
            block_align,
            bits_per_sample,
            b"data",
            data_size
        )
        
        return header + audio_data
    
    def _trim_silence(self, audio_path: str):
        """FFmpegë¡œ ì˜¤ë””ì˜¤ ëë¶€ë¶„ ì¹¨ë¬µ ì œê±°"""
        try:
            import subprocess
            
            trimmed_path = audio_path.replace(".wav", "_trimmed.wav")
            
            # silenceremove í•„í„°: ëë¶€ë¶„ì˜ ì¹¨ë¬µ(-30dB ì´í•˜) ì œê±°
            cmd = [
                "ffmpeg", "-y", "-v", "quiet",
                "-i", audio_path,
                "-af", "silenceremove=stop_periods=-1:stop_duration=1:stop_threshold=-30dB",
                trimmed_path
            ]
            
            result = subprocess.run(cmd, capture_output=True)
            
            if result.returncode == 0 and Path(trimmed_path).exists():
                # ì›ë³¸ êµì²´
                Path(trimmed_path).replace(audio_path)
                # print(f"      âœ‚ï¸ ì¹¨ë¬µ ì œê±° ì™„ë£Œ")
        except Exception as e:
            print(f"      âš ï¸ ì¹¨ë¬µ ì œê±° ì‹¤íŒ¨: {e}")

    def generate_for_section(
        self,
        section,
        output_dir: str,
        preprocess: bool = True,
        max_chunk_chars: int = 2000
    ) -> List[TTSResult]:
        """ì„¹ì…˜ë³„ TTS ìƒì„± (ê¸´ í…ìŠ¤íŠ¸ëŠ” ì²­í‚¹)"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        text = section.content
        if preprocess:
            text = self.preprocessor.process(text)
        
        # í…ìŠ¤íŠ¸ ì²­í‚¹
        chunks = self.preprocessor.split_for_tts(text, max_chars=max_chunk_chars)
        
        print(f"   ğŸ”Š ì„¹ì…˜ {section.number}: {section.title}")
        print(f"      í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}ì â†’ {len(chunks)}ê°œ ì²­í¬")
        
        results = []
        
        for chunk_idx, chunk in enumerate(chunks):
            duration_estimate = self.preprocessor.estimate_duration(chunk)
            
            # ì²­í¬ê°€ 1ê°œë©´ ê¸°ì¡´ ë°©ì‹, ì—¬ëŸ¬ ê°œë©´ ì„¹ì…˜-ì²­í¬ ë²ˆí˜¸
            if len(chunks) == 1:
                audio_file = output_path / f"audio_{section.number:02d}.wav"
                file_label = audio_file.name
            else:
                audio_file = output_path / f"audio_{section.number:02d}-{chunk_idx+1}.wav"
                file_label = f"{audio_file.name} ({len(chunk)}ì, ~{duration_estimate:.0f}ì´ˆ)"
            
            print(f"      ì²­í¬ {chunk_idx+1}/{len(chunks)}: {len(chunk)}ì, ì˜ˆìƒ: {duration_estimate:.0f}ì´ˆ...", end=" ")
            
            # TTS ìƒì„±
            success = self.generate(chunk, str(audio_file))
            
            if success:
                print("âœ…")
                results.append(TTSResult(
                    section_num=section.number,
                    audio_path=str(audio_file),
                    text=chunk,
                    duration_estimate=duration_estimate
                ))
            else:
                print("âŒ")
        
        return results
    
    def _generate_section_task(self, args) -> List[TTSResult]:
        """ë³‘ë ¬ ì²˜ë¦¬ìš© ì„¹ì…˜ TTS íƒœìŠ¤í¬"""
        section, output_path = args
        return self.generate_for_section(section, output_path)
    
    def generate_for_lecture(
        self,
        lecture,
        output_dir: str = None,
        parallel_workers: int = 2
    ) -> List[TTSResult]:
        """ì „ì²´ ê°•ì˜ TTS ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬)"""
        from concurrent.futures import ThreadPoolExecutor
        
        output_path = Path(output_dir or OUTPUT_DIR)
        output_path.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ”Š TTS ìƒì„± ì‹œì‘: {lecture.title}")
        print(f"   ëª¨ë¸: {self.model}")
        print(f"   Voice: {self.voice}")
        print(f"   ğŸš€ ë³‘ë ¬ ì²˜ë¦¬: {parallel_workers} workers")
        print()
        
        # íƒœìŠ¤í¬ ì¤€ë¹„
        tasks = [(section, str(output_path)) for section in lecture.sections]
        
        # ë³‘ë ¬ ì‹¤í–‰
        all_results = []
        with ThreadPoolExecutor(max_workers=parallel_workers) as executor:
            section_results = list(executor.map(self._generate_section_task, tasks))
        
        # ê²°ê³¼ ë³‘í•©
        for results in section_results:
            all_results.extend(results)
        
        print()
        print(f"âœ… TTS ìƒì„± ì™„ë£Œ: {len(all_results)}ê°œ ì˜¤ë””ì˜¤ íŒŒì¼")
        
        total_duration = sum(r.duration_estimate for r in all_results)
        print(f"   ì´ ì˜ˆìƒ ê¸¸ì´: {total_duration / 60:.1f}ë¶„")
        
        return all_results


def main():
    """í…ŒìŠ¤íŠ¸"""
    import sys
    sys.path.insert(0, str(Path(__file__).parent.parent))
    
    from modules.lecture_parser import LectureParser
    
    if len(sys.argv) < 2:
        print("Usage: python tts_generator.py <lecture.md>")
        sys.exit(1)
    
    parser = LectureParser()
    lecture = parser.parse(sys.argv[1])
    
    generator = TTSGenerator()
    
    # ì²« ë²ˆì§¸ ì„¹ì…˜ë§Œ í…ŒìŠ¤íŠ¸
    if lecture.sections:
        section = lecture.sections[0]
        result = generator.generate_for_section(section, "output/tts_test")
        if result:
            print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ: {result.audio_path}")


if __name__ == "__main__":
    main()
